{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit",
      "language": "python",
      "name": "python_defaultSpec_1596206907464"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "colab": {
      "name": "02-PMC_2couches-etud.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aafaf-arharas/ML_TPs/blob/main/02_PMC_2couches_etud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrYCPkJDrq8F"
      },
      "source": [
        "# Perceptron multicouches et Keras\n",
        "\n",
        "Définition d'un perceptron multicouches à deux couches cachées pour la classification de données MNIST\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmqQvPzYrq8T"
      },
      "source": [
        "## MNIST \n",
        "\n",
        "La base de données MNIST (Mixed National Institute of Standards and Technology), est une base de données de chiffres manuscrits. C’est une base de données standard pour le test de nouveaux algorithmes de reconnaissance de ces chiffres. Elle est composée de 60000 images d’apprentissage et 10000 images de test. Les images en noir et blanc, normalisées centrées de 28 pixels de côté.\n",
        "\n",
        "![mnist.png](./mnist.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKxVFQrwrq8V"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khbpfsc7rq8Z"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as tk\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Activation,Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq_YNwryrq8h"
      },
      "source": [
        "# Données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2ndFXpurq8j"
      },
      "source": [
        "On charge ensuite les données MNIST. Les paramètres de la base sont récupérés (nombre d'exemples, de classes, taille de la rétine)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKxwoTHJrq8k",
        "outputId": "15a5827e-bfc3-4436-b841-93258ce34aeb"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) =tk.datasets.mnist.load_data()\n",
        "\n",
        "num_examples = x_train.shape[0] \n",
        "num_test = x_test.shape[0]\n",
        "num_input = x_train.shape[1]*x_train.shape[2]\n",
        "num_classes = 10\n",
        "\n",
        "img_size = x_train.shape[1] \n",
        "img_shape = (img_size, img_size)\n",
        "\n",
        "x_train = x_train.reshape((num_examples, num_input))/255\n",
        "x_test  = x_test.reshape((num_test, num_input))/255\n",
        "\n",
        "# normalisation\n",
        "\n",
        "\n",
        "\n",
        "print('Taille de la rétine : ',num_input)\n",
        "print(\"Nombre d'exemples : \",num_examples)\n",
        "\n",
        "y_train = tk.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tk.utils.to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Taille de la rétine :  784\n",
            "Nombre d'exemples :  60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqe7GLM9rq8q"
      },
      "source": [
        "# Réseau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEtNaiNOrq8t"
      },
      "source": [
        "## Paramètres du réseau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4URq3mIrq8w"
      },
      "source": [
        "Dans un premier temps, on définit les paramètres du réseau : \n",
        "- 256 neurones cachés dans chaque couche cachée, \n",
        "- un apprentissage par batchs de taille 100\n",
        "- 15 itérations pour l'apprentissage\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5spn8pfIrq8y"
      },
      "source": [
        "\n",
        "lr = 0.001\n",
        "num_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "# Nombre de neurones sur les deux couches cachées\n",
        "num_hidden_1 = 256 \n",
        "num_hidden_2 = 256 "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgyUmB23rq80"
      },
      "source": [
        "## Définition du réseau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV_ZcQczrq81"
      },
      "source": [
        "On construit alors le modèle :\n",
        "- le réseau\n",
        "- la fonction de coût à optimiser : dans le cas d'un problème de classification, la fonction d'entropie croisée calculée entre la sortie théorique et la sortie calculée par le modèle est adéquate\n",
        "- la méthode d'optimisation utilisée (descente de gradient) : ici, l'algorithme [ADAM](https://arxiv.org/abs/1412.6980) est utilisé"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbkhddhZrq82",
        "outputId": "2f727796-d883-418c-cc7c-726c749daacc"
      },
      "source": [
        "#TODO : réseau\n",
        "#Définition des entrees\n",
        "entree = Input(shape=(784), name=\"input_layer\")\n",
        "x = Dense(units=num_hidden_1, name=\"dense_layer_1\")(entree)\n",
        "x = Activation('relu', name=\"activation_layer\")(x)\n",
        "\n",
        "def custom_layer(tensor):\n",
        "    return tensor + 2\n",
        "\n",
        "out = Dense(units=10, name=\"dense_layer_2\")(x)\n",
        "#x = Lambda (custom_layer, name=\"lambda_layer\")(x)\n",
        "\n",
        "\n",
        "\n",
        "# Modele\n",
        "model = Model(entree , out)\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_layer_1 (Dense)        (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "activation_layer (Activation (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer_2 (Dense)        (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWKd95s3rq84"
      },
      "source": [
        "#TODO : optimiseur et fonction de perte\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"Adam\",metrics=['acc'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPmhRQOMrq85"
      },
      "source": [
        "On entraîne le modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7NXqUHZrq87",
        "outputId": "572446cd-6497-4e89-d639-5d1167f9139a"
      },
      "source": [
        "#TODO ;: entraînement\n",
        "#Entrainement\n",
        "model.fit(x_train,y_train, batch_size =100, epochs =15)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.4942 - acc: 0.6988\n",
            "Epoch 2/15\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.5647 - acc: 0.6734\n",
            "Epoch 3/15\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.7823 - acc: 0.5250\n",
            "Epoch 4/15\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.8393 - acc: 0.4967\n",
            "Epoch 5/15\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.8265 - acc: 0.5679\n",
            "Epoch 6/15\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.9323 - acc: 0.4971\n",
            "Epoch 7/15\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 1.0068 - acc: 0.4833\n",
            "Epoch 8/15\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 1.0531 - acc: 0.4101\n",
            "Epoch 9/15\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 1.1188 - acc: 0.4670\n",
            "Epoch 10/15\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.9753 - acc: 0.5303\n",
            "Epoch 11/15\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.6714 - acc: 0.6767\n",
            "Epoch 12/15\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.6114 - acc: 0.7016\n",
            "Epoch 13/15\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.6528 - acc: 0.6785\n",
            "Epoch 14/15\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.6908 - acc: 0.6490\n",
            "Epoch 15/15\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.8762 - acc: 0.5556\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feaa14f9e10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "ILXvvBI2rq8-",
        "outputId": "498c7949-ca57-4f2b-d0b8-15e051d716e2"
      },
      "source": [
        "print(\"Précision ={0:5.3f} \".format(hist.history.get('acc')[-1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-da2389bcd57b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Précision ={0:5.3f} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP03Om2Zrq9A"
      },
      "source": [
        "Puis on l'évalue sur l'ensemble de test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "-61WFqOKrq9B",
        "outputId": "f1371216-1013-4e1e-d68b-eedab5a6f091"
      },
      "source": [
        "score = model.evaluate(x_test,y_test)\n",
        "\n",
        "x = list(range(1,num_epochs+1))\n",
        "l = hist.history['loss']\n",
        "plt.subplots(1,1)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Entropie croisée')\n",
        "plt.title(\"Test : Score = {0:5.3f}, Précision = {1:5.3f}\".format(score[0], score[1]))\n",
        "plt.plot(x,l)\n",
        "plt.show()\n",
        "plt.tight_layout()\n",
        "\n",
        "predicted_classes = np.argmax(model.predict(x_test), axis=-1)\n",
        "y = np.argmax(y_test,axis=1)\n",
        "\n",
        "incorrects = np.nonzero(predicted_classes != y)[0]\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(0,9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(x_test[incorrects[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title( \"Prédit/vrai : {}/{}\".format(predicted_classes[incorrects[i]], y[incorrects[i]]))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "plt.tight_layout()\n",
        "print(\"Nombre d'erreurs {}/{}\\n\\n\".format(incorrects.size,y.size))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7334 - acc: 0.6517\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a2403a446c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
          ]
        }
      ]
    }
  ]
}